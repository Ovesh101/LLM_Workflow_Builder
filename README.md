# LLM Workflow Builder

## Overview
LLM Workflow Builder is a web-based application that enables users to create and deploy workflows involving Large Language Models (LLMs). The workflow consists of three essential nodes: **Input**, **LLM**, and **Output**. Users can visually construct workflows by dragging and dropping nodes onto a canvas, connecting them as needed.

## Features

### **Drag-and-Drop Functionality**
- Users can drag and drop Input, LLM, and Output nodes onto a canvas.
- This makes workflow creation intuitive and easy to use.

### **Node Connections**
- Ensure that nodes are connected correctly: **Input → LLM → Output**.
- The Input node can only connect to the LLM node, and the LLM node can only connect to the Output node, ensuring logical workflow creation.

### **Input Node**
- Accepts user queries or questions.
- Validate input to ensure it's suitable for processing by the LLM.

### **LLM Node**
- Provides a user configuration interface to set OpenAI model credentials and parameters.
- Validate the configuration to ensure it is compatible with the chosen LLM.

### **Output Node**
- Displays the generated output from the LLM based on the input and configuration.

### **TOGETHER LLM**
- The **TOGETHER LLM** configuration is used to generate output. It integrates with the backend to process queries and provides accurate results based on user inputs.

---

## Complete Source Code Documentation

### **Code Architecture Overview**

The application is structured into frontend and backend components that work seamlessly together.

- **Frontend Components:**
  - **NodeInput**: Allows users to input queries and validates the input before sending it to the LLM.
  - **NodeLLM**: A configuration interface for users to input OpenAI model credentials and parameters.
  - **NodeOutput**: Displays the output generated by the LLM based on the input and configuration.
  - **WorkflowCanvas**: Handles the drag-and-drop functionality, allowing users to construct workflows by placing nodes and connecting them appropriately.

- **Backend Components:**
  - The backend uses the **TOGETHER LLM API** to process the input and generate responses based on the user-configured parameters.
  - It also handles CORS-related issues by using appropriate server-side solutions to ensure smooth integration between the frontend and backend.

---

## Setup & Installation

### Prerequisites
- Node.js (version 16 or above)
- npm or yarn
- Vercel CLI (for deployment)

### Steps to Install Locally

1. **Clone the Repository**
   ```bash
   git clone https://github.com/yourusername/llm-workflow-builder.git
   cd LLM_Workflow_Builder
   npm install
   ```
2: **Spin up the fronted and backend**
  ```
    npm run dev
    (backed I have used for calling together API to solve the cors-related issue)
  ```
## Demo Video

Watch the demo video here:
[![LLM Workflow Builder Demo](https://drive.google.com/file/d/1_IL4kbfKOhgbeBy3bS6FmmPBdkJaumSm/view?usp=sharing)


### Deployment
  For live access to the deployed version, visit: [**Live Demo on Vercel**](https://llm-workflow-builder.vercel.app/)
  
    

